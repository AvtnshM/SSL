{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Please check the previously saved versions of this notebook on - https://github.com/AvtnshM/SSL\n","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ncudnn.benchmark = True\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:50.804864Z","iopub.execute_input":"2026-02-21T06:12:50.805696Z","iopub.status.idle":"2026-02-21T06:12:50.811781Z","shell.execute_reply.started":"2026-02-21T06:12:50.805634Z","shell.execute_reply":"2026-02-21T06:12:50.810906Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# CIFAR10 normalization values\ncifar_mean = (0.4914, 0.4822, 0.4465)\ncifar_std = (0.2023, 0.1994, 0.2010)\n\nssl_transform = transforms.Compose([\n    transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomApply([\n        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n    ], p=0.8),\n    transforms.RandomGrayscale(p=0.2),\n    transforms.GaussianBlur(3),\n    transforms.ToTensor(),\n    transforms.Normalize(cifar_mean, cifar_std)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:50.813234Z","iopub.execute_input":"2026-02-21T06:12:50.813770Z","iopub.status.idle":"2026-02-21T06:12:50.829023Z","shell.execute_reply.started":"2026-02-21T06:12:50.813720Z","shell.execute_reply":"2026-02-21T06:12:50.828429Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class BYOLDataset(torch.utils.data.Dataset):\n    def __init__(self, root, train, transform):\n        self.dataset = datasets.CIFAR10(\n            root=root,\n            train=train,\n            download=True,\n            transform=None  # IMPORTANT: no transform here\n        )\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        img, _ = self.dataset[idx]   # img is PIL image\n        view1 = self.transform(img)\n        view2 = self.transform(img)\n        return view1, view2\n\n\nssl_dataset = BYOLDataset(\n    root=\"/kaggle/working/data\",\n    train=True,\n    transform=ssl_transform\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:50.829757Z","iopub.execute_input":"2026-02-21T06:12:50.830021Z","iopub.status.idle":"2026-02-21T06:12:51.804730Z","shell.execute_reply.started":"2026-02-21T06:12:50.829992Z","shell.execute_reply":"2026-02-21T06:12:51.804060Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"loader = DataLoader(\n    ssl_dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=True\n)\n\nprint(\"Batches per epoch:\", len(loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.806250Z","iopub.execute_input":"2026-02-21T06:12:51.806461Z","iopub.status.idle":"2026-02-21T06:12:51.811652Z","shell.execute_reply.started":"2026-02-21T06:12:51.806441Z","shell.execute_reply":"2026-02-21T06:12:51.811091Z"}},"outputs":[{"name":"stdout","text":"Batches per epoch: 195\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torchvision.models as models\n\nclass Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Load ResNet18\n        backbone = models.resnet18(weights=None)\n\n        # Remove final classification layer\n        self.encoder = nn.Sequential(*list(backbone.children())[:-1])\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x.view(x.size(0), -1)  # Output: (B, 512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.812441Z","iopub.execute_input":"2026-02-21T06:12:51.812728Z","iopub.status.idle":"2026-02-21T06:12:51.830601Z","shell.execute_reply.started":"2026-02-21T06:12:51.812698Z","shell.execute_reply":"2026-02-21T06:12:51.829883Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class Predictor(nn.Module):\n    def __init__(self, dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.ReLU(),\n            nn.Linear(dim, dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.831519Z","iopub.execute_input":"2026-02-21T06:12:51.831915Z","iopub.status.idle":"2026-02-21T06:12:51.845696Z","shell.execute_reply.started":"2026-02-21T06:12:51.831891Z","shell.execute_reply":"2026-02-21T06:12:51.845005Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class Projector(nn.Module):\n    def __init__(self, in_dim=512, hidden_dim=512, out_dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.846703Z","iopub.execute_input":"2026-02-21T06:12:51.846976Z","iopub.status.idle":"2026-02-21T06:12:51.860138Z","shell.execute_reply.started":"2026-02-21T06:12:51.846946Z","shell.execute_reply":"2026-02-21T06:12:51.859586Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def ssl_loss(p, z):\n    p = F.normalize(p, dim=1)\n    z = F.normalize(z, dim=1)\n    return F.mse_loss(p, z)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.860983Z","iopub.execute_input":"2026-02-21T06:12:51.861377Z","iopub.status.idle":"2026-02-21T06:12:51.873722Z","shell.execute_reply.started":"2026-02-21T06:12:51.861344Z","shell.execute_reply":"2026-02-21T06:12:51.873068Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"encoder = Encoder().to(device)\nprojector = Projector().to(device)\npredictor = Predictor().to(device)\n\ntarget_encoder = Encoder().to(device)\ntarget_encoder.load_state_dict(encoder.state_dict())\n\nfor p in target_encoder.parameters():\n    p.requires_grad = False\n\noptimizer = torch.optim.Adam(\n    list(encoder.parameters()) +\n    list(projector.parameters()) +\n    list(predictor.parameters()),\n    lr=1e-3\n)\n\nema_tau = 0.996\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:51.874698Z","iopub.execute_input":"2026-02-21T06:12:51.874962Z","iopub.status.idle":"2026-02-21T06:12:52.228876Z","shell.execute_reply.started":"2026-02-21T06:12:51.874940Z","shell.execute_reply":"2026-02-21T06:12:52.228164Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"@torch.no_grad()\ndef feature_variance(z):\n    return z.var(dim=0).mean().item()\n\n@torch.no_grad()\ndef cosine_similarity_mean(z1, z2):\n    z1 = F.normalize(z1, dim=1)\n    z2 = F.normalize(z2, dim=1)\n    return (z1 * z2).sum(dim=1).mean().item()\n\n@torch.no_grad()\ndef update_target_encoder(online, target, tau):\n    for op, tp in zip(online.parameters(), target.parameters()):\n        tp.data = tau * tp.data + (1 - tau) * op.data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:52.230853Z","iopub.execute_input":"2026-02-21T06:12:52.231078Z","iopub.status.idle":"2026-02-21T06:12:52.236515Z","shell.execute_reply.started":"2026-02-21T06:12:52.231057Z","shell.execute_reply":"2026-02-21T06:12:52.236005Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"epochs = 100\nos.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n\ntotal_start_time = time.time()\n\nfor epoch in range(epochs):\n\n    epoch_start = time.time()\n\n    total_loss, total_var, total_cos = 0.0, 0.0, 0.0\n\n    for view1, view2 in loader:\n\n        view1 = view1.to(device)\n        view2 = view2.to(device)\n\n        z1 = encoder(view1)\n        z2 = encoder(view2)\n\n        h1 = projector(z1)\n        h2 = projector(z2)\n\n        p1 = predictor(h1)\n        p2 = predictor(h2)\n\n        with torch.no_grad():\n            t1 = projector(target_encoder(view1))\n            t2 = projector(target_encoder(view2))\n\n        loss = ssl_loss(p1, t2.detach()) + ssl_loss(p2, t1.detach())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        update_target_encoder(encoder, target_encoder, ema_tau)\n\n        with torch.no_grad():\n            total_var += feature_variance(z1)\n            total_cos += cosine_similarity_mean(z1, z2)\n\n        total_loss += loss.item()\n\n    epoch_time = (time.time() - epoch_start) / 60\n    total_time = (time.time() - total_start_time) / 60\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Loss {total_loss/len(loader):.4f} | \"\n        f\"Var {total_var/len(loader):.4f} | \"\n        f\"Cos {total_cos/len(loader):.4f} | \"\n        f\"Epoch Time {epoch_time:.2f} min | \"\n        f\"Total Time {total_time:.2f} min\"\n    )\n\n# Save only final model (avoid 5GB explosion)\ntorch.save(encoder.state_dict(), \"/kaggle/working/encoder_final.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:12:52.237412Z","iopub.execute_input":"2026-02-21T06:12:52.237615Z","iopub.status.idle":"2026-02-21T08:06:05.220845Z","shell.execute_reply.started":"2026-02-21T06:12:52.237595Z","shell.execute_reply":"2026-02-21T08:06:05.219540Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100 | Loss 0.0010 | Var 2.4694 | Cos 0.6874 | Epoch Time 1.12 min | Total Time 1.12 min\nEpoch 2/100 | Loss 0.0007 | Var 2.4105 | Cos 0.7370 | Epoch Time 1.12 min | Total Time 2.24 min\nEpoch 3/100 | Loss 0.0009 | Var 2.2976 | Cos 0.7549 | Epoch Time 1.12 min | Total Time 3.36 min\nEpoch 4/100 | Loss 0.0011 | Var 2.1429 | Cos 0.7708 | Epoch Time 1.12 min | Total Time 4.49 min\nEpoch 5/100 | Loss 0.0012 | Var 2.0685 | Cos 0.7911 | Epoch Time 1.12 min | Total Time 5.61 min\nEpoch 6/100 | Loss 0.0013 | Var 2.0318 | Cos 0.8032 | Epoch Time 1.13 min | Total Time 6.73 min\nEpoch 7/100 | Loss 0.0014 | Var 2.0265 | Cos 0.8161 | Epoch Time 1.14 min | Total Time 7.87 min\nEpoch 8/100 | Loss 0.0015 | Var 2.0014 | Cos 0.8202 | Epoch Time 1.13 min | Total Time 9.00 min\nEpoch 9/100 | Loss 0.0016 | Var 1.9696 | Cos 0.8273 | Epoch Time 1.13 min | Total Time 10.13 min\nEpoch 10/100 | Loss 0.0016 | Var 1.9688 | Cos 0.8347 | Epoch Time 1.13 min | Total Time 11.27 min\nEpoch 11/100 | Loss 0.0016 | Var 1.9442 | Cos 0.8413 | Epoch Time 1.13 min | Total Time 12.40 min\nEpoch 12/100 | Loss 0.0016 | Var 1.9152 | Cos 0.8438 | Epoch Time 1.13 min | Total Time 13.53 min\nEpoch 13/100 | Loss 0.0016 | Var 1.9016 | Cos 0.8479 | Epoch Time 1.12 min | Total Time 14.65 min\nEpoch 14/100 | Loss 0.0017 | Var 1.8888 | Cos 0.8494 | Epoch Time 1.13 min | Total Time 15.78 min\nEpoch 15/100 | Loss 0.0016 | Var 1.8437 | Cos 0.8542 | Epoch Time 1.12 min | Total Time 16.90 min\nEpoch 16/100 | Loss 0.0016 | Var 1.8543 | Cos 0.8554 | Epoch Time 1.13 min | Total Time 18.02 min\nEpoch 17/100 | Loss 0.0016 | Var 1.8303 | Cos 0.8575 | Epoch Time 1.12 min | Total Time 19.15 min\nEpoch 18/100 | Loss 0.0016 | Var 1.8302 | Cos 0.8592 | Epoch Time 1.12 min | Total Time 20.27 min\nEpoch 19/100 | Loss 0.0016 | Var 1.8089 | Cos 0.8592 | Epoch Time 1.13 min | Total Time 21.40 min\nEpoch 20/100 | Loss 0.0016 | Var 1.7940 | Cos 0.8623 | Epoch Time 1.13 min | Total Time 22.53 min\nEpoch 21/100 | Loss 0.0016 | Var 1.7857 | Cos 0.8631 | Epoch Time 1.13 min | Total Time 23.66 min\nEpoch 22/100 | Loss 0.0016 | Var 1.7866 | Cos 0.8641 | Epoch Time 1.13 min | Total Time 24.79 min\nEpoch 23/100 | Loss 0.0016 | Var 1.7702 | Cos 0.8643 | Epoch Time 1.14 min | Total Time 25.93 min\nEpoch 24/100 | Loss 0.0016 | Var 1.7546 | Cos 0.8660 | Epoch Time 1.13 min | Total Time 27.06 min\nEpoch 25/100 | Loss 0.0016 | Var 1.7231 | Cos 0.8658 | Epoch Time 1.13 min | Total Time 28.18 min\nEpoch 26/100 | Loss 0.0016 | Var 1.7005 | Cos 0.8675 | Epoch Time 1.13 min | Total Time 29.32 min\nEpoch 27/100 | Loss 0.0016 | Var 1.6816 | Cos 0.8690 | Epoch Time 1.13 min | Total Time 30.45 min\nEpoch 28/100 | Loss 0.0016 | Var 1.6675 | Cos 0.8727 | Epoch Time 1.14 min | Total Time 31.59 min\nEpoch 29/100 | Loss 0.0016 | Var 1.6701 | Cos 0.8726 | Epoch Time 1.15 min | Total Time 32.73 min\nEpoch 30/100 | Loss 0.0016 | Var 1.6529 | Cos 0.8722 | Epoch Time 1.14 min | Total Time 33.88 min\nEpoch 31/100 | Loss 0.0016 | Var 1.6514 | Cos 0.8747 | Epoch Time 1.14 min | Total Time 35.02 min\nEpoch 32/100 | Loss 0.0016 | Var 1.6447 | Cos 0.8738 | Epoch Time 1.14 min | Total Time 36.16 min\nEpoch 33/100 | Loss 0.0016 | Var 1.6320 | Cos 0.8760 | Epoch Time 1.13 min | Total Time 37.29 min\nEpoch 34/100 | Loss 0.0016 | Var 1.6141 | Cos 0.8760 | Epoch Time 1.13 min | Total Time 38.42 min\nEpoch 35/100 | Loss 0.0015 | Var 1.6055 | Cos 0.8782 | Epoch Time 1.13 min | Total Time 39.56 min\nEpoch 36/100 | Loss 0.0015 | Var 1.5785 | Cos 0.8774 | Epoch Time 1.14 min | Total Time 40.70 min\nEpoch 37/100 | Loss 0.0015 | Var 1.5621 | Cos 0.8793 | Epoch Time 1.12 min | Total Time 41.82 min\nEpoch 38/100 | Loss 0.0014 | Var 1.5395 | Cos 0.8815 | Epoch Time 1.14 min | Total Time 42.96 min\nEpoch 39/100 | Loss 0.0014 | Var 1.5381 | Cos 0.8825 | Epoch Time 1.14 min | Total Time 44.10 min\nEpoch 40/100 | Loss 0.0014 | Var 1.5346 | Cos 0.8835 | Epoch Time 1.14 min | Total Time 45.24 min\nEpoch 41/100 | Loss 0.0014 | Var 1.5226 | Cos 0.8837 | Epoch Time 1.14 min | Total Time 46.38 min\nEpoch 42/100 | Loss 0.0014 | Var 1.5164 | Cos 0.8850 | Epoch Time 1.14 min | Total Time 47.52 min\nEpoch 43/100 | Loss 0.0014 | Var 1.5015 | Cos 0.8849 | Epoch Time 1.13 min | Total Time 48.65 min\nEpoch 44/100 | Loss 0.0014 | Var 1.4989 | Cos 0.8865 | Epoch Time 1.14 min | Total Time 49.79 min\nEpoch 45/100 | Loss 0.0014 | Var 1.4805 | Cos 0.8870 | Epoch Time 1.15 min | Total Time 50.94 min\nEpoch 46/100 | Loss 0.0013 | Var 1.4766 | Cos 0.8880 | Epoch Time 1.14 min | Total Time 52.09 min\nEpoch 47/100 | Loss 0.0013 | Var 1.4651 | Cos 0.8889 | Epoch Time 1.14 min | Total Time 53.22 min\nEpoch 48/100 | Loss 0.0013 | Var 1.4529 | Cos 0.8895 | Epoch Time 1.14 min | Total Time 54.36 min\nEpoch 49/100 | Loss 0.0013 | Var 1.4444 | Cos 0.8901 | Epoch Time 1.13 min | Total Time 55.49 min\nEpoch 50/100 | Loss 0.0013 | Var 1.4393 | Cos 0.8915 | Epoch Time 1.13 min | Total Time 56.62 min\nEpoch 51/100 | Loss 0.0013 | Var 1.4338 | Cos 0.8909 | Epoch Time 1.14 min | Total Time 57.76 min\nEpoch 52/100 | Loss 0.0013 | Var 1.4152 | Cos 0.8927 | Epoch Time 1.14 min | Total Time 58.90 min\nEpoch 53/100 | Loss 0.0013 | Var 1.4086 | Cos 0.8936 | Epoch Time 1.14 min | Total Time 60.04 min\nEpoch 54/100 | Loss 0.0013 | Var 1.4038 | Cos 0.8942 | Epoch Time 1.14 min | Total Time 61.18 min\nEpoch 55/100 | Loss 0.0013 | Var 1.3959 | Cos 0.8941 | Epoch Time 1.14 min | Total Time 62.32 min\nEpoch 56/100 | Loss 0.0013 | Var 1.3839 | Cos 0.8944 | Epoch Time 1.14 min | Total Time 63.46 min\nEpoch 57/100 | Loss 0.0013 | Var 1.3684 | Cos 0.8950 | Epoch Time 1.13 min | Total Time 64.59 min\nEpoch 58/100 | Loss 0.0013 | Var 1.3640 | Cos 0.8958 | Epoch Time 1.13 min | Total Time 65.73 min\nEpoch 59/100 | Loss 0.0013 | Var 1.3467 | Cos 0.8960 | Epoch Time 1.13 min | Total Time 66.85 min\nEpoch 60/100 | Loss 0.0013 | Var 1.3417 | Cos 0.8961 | Epoch Time 1.12 min | Total Time 67.98 min\nEpoch 61/100 | Loss 0.0013 | Var 1.3402 | Cos 0.8974 | Epoch Time 1.13 min | Total Time 69.11 min\nEpoch 62/100 | Loss 0.0013 | Var 1.3310 | Cos 0.8967 | Epoch Time 1.13 min | Total Time 70.25 min\nEpoch 63/100 | Loss 0.0012 | Var 1.3319 | Cos 0.8980 | Epoch Time 1.15 min | Total Time 71.39 min\nEpoch 64/100 | Loss 0.0012 | Var 1.3190 | Cos 0.8982 | Epoch Time 1.13 min | Total Time 72.52 min\nEpoch 65/100 | Loss 0.0012 | Var 1.3170 | Cos 0.8993 | Epoch Time 1.12 min | Total Time 73.65 min\nEpoch 66/100 | Loss 0.0012 | Var 1.3119 | Cos 0.8995 | Epoch Time 1.12 min | Total Time 74.77 min\nEpoch 67/100 | Loss 0.0012 | Var 1.3083 | Cos 0.8990 | Epoch Time 1.12 min | Total Time 75.89 min\nEpoch 68/100 | Loss 0.0012 | Var 1.3025 | Cos 0.8991 | Epoch Time 1.13 min | Total Time 77.02 min\nEpoch 69/100 | Loss 0.0012 | Var 1.2882 | Cos 0.9002 | Epoch Time 1.13 min | Total Time 78.16 min\nEpoch 70/100 | Loss 0.0012 | Var 1.2822 | Cos 0.9001 | Epoch Time 1.13 min | Total Time 79.28 min\nEpoch 71/100 | Loss 0.0012 | Var 1.2758 | Cos 0.9009 | Epoch Time 1.13 min | Total Time 80.41 min\nEpoch 72/100 | Loss 0.0012 | Var 1.2776 | Cos 0.9008 | Epoch Time 1.12 min | Total Time 81.54 min\nEpoch 73/100 | Loss 0.0012 | Var 1.2687 | Cos 0.9017 | Epoch Time 1.13 min | Total Time 82.67 min\nEpoch 74/100 | Loss 0.0012 | Var 1.2732 | Cos 0.9025 | Epoch Time 1.13 min | Total Time 83.79 min\nEpoch 75/100 | Loss 0.0012 | Var 1.2685 | Cos 0.9023 | Epoch Time 1.13 min | Total Time 84.92 min\nEpoch 76/100 | Loss 0.0012 | Var 1.2626 | Cos 0.9019 | Epoch Time 1.12 min | Total Time 86.05 min\nEpoch 77/100 | Loss 0.0012 | Var 1.2522 | Cos 0.9037 | Epoch Time 1.13 min | Total Time 87.18 min\nEpoch 78/100 | Loss 0.0012 | Var 1.2531 | Cos 0.9029 | Epoch Time 1.13 min | Total Time 88.31 min\nEpoch 79/100 | Loss 0.0012 | Var 1.2537 | Cos 0.9039 | Epoch Time 1.13 min | Total Time 89.44 min\nEpoch 80/100 | Loss 0.0012 | Var 1.2494 | Cos 0.9038 | Epoch Time 1.13 min | Total Time 90.57 min\nEpoch 81/100 | Loss 0.0012 | Var 1.2461 | Cos 0.9042 | Epoch Time 1.13 min | Total Time 91.69 min\nEpoch 82/100 | Loss 0.0012 | Var 1.2512 | Cos 0.9043 | Epoch Time 1.13 min | Total Time 92.83 min\nEpoch 83/100 | Loss 0.0011 | Var 1.2500 | Cos 0.9050 | Epoch Time 1.13 min | Total Time 93.96 min\nEpoch 84/100 | Loss 0.0012 | Var 1.2461 | Cos 0.9048 | Epoch Time 1.13 min | Total Time 95.09 min\nEpoch 85/100 | Loss 0.0011 | Var 1.2420 | Cos 0.9056 | Epoch Time 1.13 min | Total Time 96.22 min\nEpoch 86/100 | Loss 0.0011 | Var 1.2344 | Cos 0.9060 | Epoch Time 1.13 min | Total Time 97.34 min\nEpoch 87/100 | Loss 0.0011 | Var 1.2356 | Cos 0.9061 | Epoch Time 1.13 min | Total Time 98.48 min\nEpoch 88/100 | Loss 0.0011 | Var 1.2313 | Cos 0.9069 | Epoch Time 1.12 min | Total Time 99.60 min\nEpoch 89/100 | Loss 0.0011 | Var 1.2259 | Cos 0.9071 | Epoch Time 1.13 min | Total Time 100.74 min\nEpoch 90/100 | Loss 0.0011 | Var 1.2196 | Cos 0.9062 | Epoch Time 1.14 min | Total Time 101.87 min\nEpoch 91/100 | Loss 0.0011 | Var 1.2149 | Cos 0.9072 | Epoch Time 1.14 min | Total Time 103.01 min\nEpoch 92/100 | Loss 0.0011 | Var 1.2158 | Cos 0.9068 | Epoch Time 1.13 min | Total Time 104.14 min\nEpoch 93/100 | Loss 0.0011 | Var 1.2102 | Cos 0.9078 | Epoch Time 1.14 min | Total Time 105.28 min\nEpoch 94/100 | Loss 0.0011 | Var 1.2088 | Cos 0.9078 | Epoch Time 1.14 min | Total Time 106.41 min\nEpoch 95/100 | Loss 0.0011 | Var 1.2142 | Cos 0.9064 | Epoch Time 1.13 min | Total Time 107.54 min\nEpoch 96/100 | Loss 0.0011 | Var 1.2116 | Cos 0.9075 | Epoch Time 1.13 min | Total Time 108.68 min\nEpoch 97/100 | Loss 0.0011 | Var 1.2098 | Cos 0.9085 | Epoch Time 1.14 min | Total Time 109.81 min\nEpoch 98/100 | Loss 0.0011 | Var 1.2075 | Cos 0.9083 | Epoch Time 1.13 min | Total Time 110.95 min\nEpoch 99/100 | Loss 0.0010 | Var 1.2029 | Cos 0.9081 | Epoch Time 1.13 min | Total Time 112.08 min\nEpoch 100/100 | Loss 0.0010 | Var 1.1978 | Cos 0.9081 | Epoch Time 1.14 min | Total Time 113.21 min\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from torchvision import datasets, transforms\n\n# Probe transform (NO augmentation, only normalization)\nprobe_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(cifar_mean, cifar_std)\n])\n\ntrain_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=True,\n    download=False,\n    transform=probe_transform\n)\n\ntest_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=False,\n    download=False,\n    transform=probe_transform\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=256,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n\nprint(\"Train batches:\", len(train_loader))\nprint(\"Test batches:\", len(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:06:05.222383Z","iopub.execute_input":"2026-02-21T08:06:05.222915Z","iopub.status.idle":"2026-02-21T08:06:06.254804Z","shell.execute_reply.started":"2026-02-21T08:06:05.222876Z","shell.execute_reply":"2026-02-21T08:06:06.254138Z"}},"outputs":[{"name":"stdout","text":"Train batches: 196\nTest batches: 40\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Load final SSL weights\nencoder = Encoder().to(device)\nencoder.load_state_dict(torch.load(\"/kaggle/working/encoder_final.pt\"))\nencoder.eval()\n\n# Freeze encoder\nfor p in encoder.parameters():\n    p.requires_grad = False\n\nprint(\"Encoder loaded and frozen.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:06:06.255613Z","iopub.execute_input":"2026-02-21T08:06:06.255904Z","iopub.status.idle":"2026-02-21T08:06:06.482262Z","shell.execute_reply.started":"2026-02-21T08:06:06.255881Z","shell.execute_reply":"2026-02-21T08:06:06.481536Z"}},"outputs":[{"name":"stdout","text":"Encoder loaded and frozen.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"\nclass LinearProbe(nn.Module):\n    def __init__(self, in_dim=512, num_classes=10):\n        super().__init__()\n        self.fc = nn.Linear(in_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\nprobe = LinearProbe(in_dim=512).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(probe.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:06:06.483239Z","iopub.execute_input":"2026-02-21T08:06:06.483510Z","iopub.status.idle":"2026-02-21T08:06:06.490109Z","shell.execute_reply.started":"2026-02-21T08:06:06.483485Z","shell.execute_reply":"2026-02-21T08:06:06.489449Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"probe_epochs = 100\n\nfor epoch in range(probe_epochs):\n    probe.train()\n    total_loss = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            features = encoder(images)\n\n        outputs = probe(features)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Probe Epoch {epoch+1}/{probe_epochs} | Loss {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:06:06.491180Z","iopub.execute_input":"2026-02-21T08:06:06.491419Z","iopub.status.idle":"2026-02-21T08:15:36.350873Z","shell.execute_reply.started":"2026-02-21T08:06:06.491397Z","shell.execute_reply":"2026-02-21T08:15:36.349900Z"}},"outputs":[{"name":"stdout","text":"Probe Epoch 1/100 | Loss 1.3938\nProbe Epoch 2/100 | Loss 1.2947\nProbe Epoch 3/100 | Loss 1.2727\nProbe Epoch 4/100 | Loss 1.2622\nProbe Epoch 5/100 | Loss 1.2535\nProbe Epoch 6/100 | Loss 1.2488\nProbe Epoch 7/100 | Loss 1.2394\nProbe Epoch 8/100 | Loss 1.2366\nProbe Epoch 9/100 | Loss 1.2320\nProbe Epoch 10/100 | Loss 1.2262\nProbe Epoch 11/100 | Loss 1.2262\nProbe Epoch 12/100 | Loss 1.2260\nProbe Epoch 13/100 | Loss 1.2180\nProbe Epoch 14/100 | Loss 1.2171\nProbe Epoch 15/100 | Loss 1.2148\nProbe Epoch 16/100 | Loss 1.2114\nProbe Epoch 17/100 | Loss 1.2084\nProbe Epoch 18/100 | Loss 1.2088\nProbe Epoch 19/100 | Loss 1.2090\nProbe Epoch 20/100 | Loss 1.2048\nProbe Epoch 21/100 | Loss 1.2020\nProbe Epoch 22/100 | Loss 1.2022\nProbe Epoch 23/100 | Loss 1.1989\nProbe Epoch 24/100 | Loss 1.1989\nProbe Epoch 25/100 | Loss 1.1958\nProbe Epoch 26/100 | Loss 1.1993\nProbe Epoch 27/100 | Loss 1.1943\nProbe Epoch 28/100 | Loss 1.1922\nProbe Epoch 29/100 | Loss 1.1942\nProbe Epoch 30/100 | Loss 1.1906\nProbe Epoch 31/100 | Loss 1.1899\nProbe Epoch 32/100 | Loss 1.1877\nProbe Epoch 33/100 | Loss 1.1885\nProbe Epoch 34/100 | Loss 1.1891\nProbe Epoch 35/100 | Loss 1.1840\nProbe Epoch 36/100 | Loss 1.1861\nProbe Epoch 37/100 | Loss 1.1842\nProbe Epoch 38/100 | Loss 1.1830\nProbe Epoch 39/100 | Loss 1.1821\nProbe Epoch 40/100 | Loss 1.1824\nProbe Epoch 41/100 | Loss 1.1803\nProbe Epoch 42/100 | Loss 1.1815\nProbe Epoch 43/100 | Loss 1.1783\nProbe Epoch 44/100 | Loss 1.1791\nProbe Epoch 45/100 | Loss 1.1816\nProbe Epoch 46/100 | Loss 1.1763\nProbe Epoch 47/100 | Loss 1.1774\nProbe Epoch 48/100 | Loss 1.1778\nProbe Epoch 49/100 | Loss 1.1759\nProbe Epoch 50/100 | Loss 1.1737\nProbe Epoch 51/100 | Loss 1.1751\nProbe Epoch 52/100 | Loss 1.1720\nProbe Epoch 53/100 | Loss 1.1734\nProbe Epoch 54/100 | Loss 1.1715\nProbe Epoch 55/100 | Loss 1.1718\nProbe Epoch 56/100 | Loss 1.1703\nProbe Epoch 57/100 | Loss 1.1704\nProbe Epoch 58/100 | Loss 1.1716\nProbe Epoch 59/100 | Loss 1.1711\nProbe Epoch 60/100 | Loss 1.1699\nProbe Epoch 61/100 | Loss 1.1680\nProbe Epoch 62/100 | Loss 1.1675\nProbe Epoch 63/100 | Loss 1.1639\nProbe Epoch 64/100 | Loss 1.1667\nProbe Epoch 65/100 | Loss 1.1663\nProbe Epoch 66/100 | Loss 1.1667\nProbe Epoch 67/100 | Loss 1.1628\nProbe Epoch 68/100 | Loss 1.1658\nProbe Epoch 69/100 | Loss 1.1631\nProbe Epoch 70/100 | Loss 1.1643\nProbe Epoch 71/100 | Loss 1.1656\nProbe Epoch 72/100 | Loss 1.1664\nProbe Epoch 73/100 | Loss 1.1652\nProbe Epoch 74/100 | Loss 1.1623\nProbe Epoch 75/100 | Loss 1.1632\nProbe Epoch 76/100 | Loss 1.1621\nProbe Epoch 77/100 | Loss 1.1618\nProbe Epoch 78/100 | Loss 1.1620\nProbe Epoch 79/100 | Loss 1.1594\nProbe Epoch 80/100 | Loss 1.1597\nProbe Epoch 81/100 | Loss 1.1588\nProbe Epoch 82/100 | Loss 1.1592\nProbe Epoch 83/100 | Loss 1.1601\nProbe Epoch 84/100 | Loss 1.1578\nProbe Epoch 85/100 | Loss 1.1577\nProbe Epoch 86/100 | Loss 1.1574\nProbe Epoch 87/100 | Loss 1.1561\nProbe Epoch 88/100 | Loss 1.1571\nProbe Epoch 89/100 | Loss 1.1582\nProbe Epoch 90/100 | Loss 1.1556\nProbe Epoch 91/100 | Loss 1.1589\nProbe Epoch 92/100 | Loss 1.1551\nProbe Epoch 93/100 | Loss 1.1594\nProbe Epoch 94/100 | Loss 1.1578\nProbe Epoch 95/100 | Loss 1.1547\nProbe Epoch 96/100 | Loss 1.1547\nProbe Epoch 97/100 | Loss 1.1539\nProbe Epoch 98/100 | Loss 1.1530\nProbe Epoch 99/100 | Loss 1.1548\nProbe Epoch 100/100 | Loss 1.1526\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"probe.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        features = encoder(images)\n        outputs = probe(features)\n\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"\\nðŸ”¹ Linear Probe Test Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T08:15:36.352151Z","iopub.execute_input":"2026-02-21T08:15:36.352404Z","iopub.status.idle":"2026-02-21T08:15:37.639584Z","shell.execute_reply.started":"2026-02-21T08:15:36.352376Z","shell.execute_reply":"2026-02-21T08:15:37.638779Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Linear Probe Test Accuracy: 56.01%\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}