{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ncudnn.benchmark = True\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:04.938538Z","iopub.execute_input":"2026-02-20T04:38:04.938867Z","iopub.status.idle":"2026-02-20T04:38:13.350165Z","shell.execute_reply.started":"2026-02-20T04:38:04.938831Z","shell.execute_reply":"2026-02-20T04:38:13.349412Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"base_transform = transforms.ToTensor()\n\nssl_transform = transforms.Compose([\n    transforms.RandomResizedCrop(32),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n    transforms.ToTensor()\n])\n\nto_pil = transforms.ToPILImage()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:13.351789Z","iopub.execute_input":"2026-02-20T04:38:13.352518Z","iopub.status.idle":"2026-02-20T04:38:13.357463Z","shell.execute_reply.started":"2026-02-20T04:38:13.352491Z","shell.execute_reply":"2026-02-20T04:38:13.356682Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=True,\n    download=True,\n    transform=base_transform\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:13.358418Z","iopub.execute_input":"2026-02-20T04:38:13.358773Z","iopub.status.idle":"2026-02-20T04:38:14.409789Z","shell.execute_reply.started":"2026-02-20T04:38:13.358700Z","shell.execute_reply":"2026-02-20T04:38:14.409138Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"loader = DataLoader(\n    dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=True\n)\n\nprint(\"Batches per epoch:\", len(loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.410774Z","iopub.execute_input":"2026-02-20T04:38:14.411109Z","iopub.status.idle":"2026-02-20T04:38:14.416619Z","shell.execute_reply.started":"2026-02-20T04:38:14.411076Z","shell.execute_reply":"2026-02-20T04:38:14.415781Z"}},"outputs":[{"name":"stdout","text":"Batches per epoch: 195\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torchvision.models as models\n\nclass Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Load ResNet18\n        backbone = models.resnet18(weights=None)\n\n        # Remove final classification layer\n        self.encoder = nn.Sequential(*list(backbone.children())[:-1])\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x.view(x.size(0), -1)  # Output: (B, 512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.417561Z","iopub.execute_input":"2026-02-20T04:38:14.417874Z","iopub.status.idle":"2026-02-20T04:38:14.428194Z","shell.execute_reply.started":"2026-02-20T04:38:14.417832Z","shell.execute_reply":"2026-02-20T04:38:14.427405Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Predictor(nn.Module):\n    def __init__(self, dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.ReLU(),\n            nn.Linear(dim, dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.429051Z","iopub.execute_input":"2026-02-20T04:38:14.429345Z","iopub.status.idle":"2026-02-20T04:38:14.439007Z","shell.execute_reply.started":"2026-02-20T04:38:14.429323Z","shell.execute_reply":"2026-02-20T04:38:14.438297Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Projector(nn.Module):\n    def __init__(self, in_dim=512, hidden_dim=512, out_dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.441146Z","iopub.execute_input":"2026-02-20T04:38:14.441391Z","iopub.status.idle":"2026-02-20T04:38:14.450246Z","shell.execute_reply.started":"2026-02-20T04:38:14.441357Z","shell.execute_reply":"2026-02-20T04:38:14.449482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def ssl_loss(p, z):\n    p = F.normalize(p, dim=1)\n    z = F.normalize(z, dim=1)\n    return F.mse_loss(p, z)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.451161Z","iopub.execute_input":"2026-02-20T04:38:14.451402Z","iopub.status.idle":"2026-02-20T04:38:14.462434Z","shell.execute_reply.started":"2026-02-20T04:38:14.451380Z","shell.execute_reply":"2026-02-20T04:38:14.461780Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"encoder = Encoder().to(device)\nprojector = Projector().to(device)\npredictor = Predictor().to(device)\n\ntarget_encoder = Encoder().to(device)\ntarget_encoder.load_state_dict(encoder.state_dict())\n\nfor p in target_encoder.parameters():\n    p.requires_grad = False\n\noptimizer = torch.optim.Adam(\n    list(encoder.parameters()) +\n    list(projector.parameters()) +\n    list(predictor.parameters()),\n    lr=1e-3\n)\n\nema_tau = 0.99\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.463296Z","iopub.execute_input":"2026-02-20T04:38:14.463558Z","iopub.status.idle":"2026-02-20T04:38:15.129829Z","shell.execute_reply.started":"2026-02-20T04:38:14.463531Z","shell.execute_reply":"2026-02-20T04:38:15.129212Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"@torch.no_grad()\ndef feature_variance(z):\n    return z.var(dim=0).mean().item()\n\n@torch.no_grad()\ndef cosine_similarity_mean(z1, z2):\n    z1 = F.normalize(z1, dim=1)\n    z2 = F.normalize(z2, dim=1)\n    return (z1 * z2).sum(dim=1).mean().item()\n\n@torch.no_grad()\ndef update_target_encoder(online, target, tau):\n    for op, tp in zip(online.parameters(), target.parameters()):\n        tp.data = tau * tp.data + (1 - tau) * op.data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:15.130724Z","iopub.execute_input":"2026-02-20T04:38:15.130957Z","iopub.status.idle":"2026-02-20T04:38:15.136775Z","shell.execute_reply.started":"2026-02-20T04:38:15.130935Z","shell.execute_reply":"2026-02-20T04:38:15.136029Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"epochs = 100\nos.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n\nfor epoch in range(epochs):\n    start = time.time()\n\n    total_loss, total_var, total_cos = 0.0, 0.0, 0.0\n\n    for images, _ in loader:\n        images = images.to(device)\n\n        view1 = torch.stack([\n            ssl_transform(to_pil(img.cpu())) for img in images\n        ]).to(device)\n\n        view2 = torch.stack([\n            ssl_transform(to_pil(img.cpu())) for img in images\n        ]).to(device)\n\n        z1 = encoder(view1)\n        z2 = encoder(view2)\n\n        h1 = projector(z1)\n        h2 = projector(z2)\n\n        p1 = predictor(h1)\n        p2 = predictor(h2)\n\n        with torch.no_grad():\n            t1 = projector(target_encoder(view1))\n            t2 = projector(target_encoder(view2))\n\n        loss = ssl_loss(p1, t2.detach()) + ssl_loss(p2, t1.detach())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        update_target_encoder(encoder, target_encoder, ema_tau)\n\n        with torch.no_grad():\n            total_var += feature_variance(z1)\n            total_cos += cosine_similarity_mean(z1, z2)\n\n        total_loss += loss.item()\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Loss {total_loss/len(loader):.4f} | \"\n        f\"Var {total_var/len(loader):.4f} | \"\n        f\"Cos {total_cos/len(loader):.4f} | \"\n        f\"Time {(time.time()-start)/60:.2f} min\"\n    )\n\n    torch.save(\n        encoder.state_dict(),\n        f\"/kaggle/working/checkpoints/encoder_epoch_{epoch+1}.pt\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:15.137603Z","iopub.execute_input":"2026-02-20T04:38:15.137982Z","iopub.status.idle":"2026-02-20T07:54:35.111192Z","shell.execute_reply.started":"2026-02-20T04:38:15.137951Z","shell.execute_reply":"2026-02-20T07:54:35.110306Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100 | Loss 0.0008 | Var 2.0138 | Cos 0.6514 | Time 2.05 min\nEpoch 2/100 | Loss 0.0006 | Var 1.9284 | Cos 0.7996 | Time 1.97 min\nEpoch 3/100 | Loss 0.0007 | Var 1.8682 | Cos 0.8518 | Time 1.96 min\nEpoch 4/100 | Loss 0.0007 | Var 1.8330 | Cos 0.8723 | Time 1.96 min\nEpoch 5/100 | Loss 0.0008 | Var 1.7911 | Cos 0.8809 | Time 1.96 min\nEpoch 6/100 | Loss 0.0008 | Var 1.7755 | Cos 0.8899 | Time 1.96 min\nEpoch 7/100 | Loss 0.0009 | Var 1.7093 | Cos 0.8940 | Time 1.96 min\nEpoch 8/100 | Loss 0.0010 | Var 1.6825 | Cos 0.8982 | Time 1.96 min\nEpoch 9/100 | Loss 0.0012 | Var 1.6856 | Cos 0.9014 | Time 1.96 min\nEpoch 10/100 | Loss 0.0012 | Var 1.6639 | Cos 0.9029 | Time 1.96 min\nEpoch 11/100 | Loss 0.0013 | Var 1.6374 | Cos 0.9048 | Time 1.96 min\nEpoch 12/100 | Loss 0.0014 | Var 1.6390 | Cos 0.9069 | Time 1.96 min\nEpoch 13/100 | Loss 0.0014 | Var 1.6107 | Cos 0.9112 | Time 1.96 min\nEpoch 14/100 | Loss 0.0014 | Var 1.5989 | Cos 0.9123 | Time 1.96 min\nEpoch 15/100 | Loss 0.0014 | Var 1.5739 | Cos 0.9129 | Time 1.96 min\nEpoch 16/100 | Loss 0.0014 | Var 1.5502 | Cos 0.9135 | Time 1.96 min\nEpoch 17/100 | Loss 0.0014 | Var 1.5208 | Cos 0.9151 | Time 1.96 min\nEpoch 18/100 | Loss 0.0014 | Var 1.5195 | Cos 0.9141 | Time 1.96 min\nEpoch 19/100 | Loss 0.0014 | Var 1.5154 | Cos 0.9158 | Time 1.96 min\nEpoch 20/100 | Loss 0.0014 | Var 1.4931 | Cos 0.9156 | Time 1.96 min\nEpoch 21/100 | Loss 0.0014 | Var 1.4778 | Cos 0.9160 | Time 1.96 min\nEpoch 22/100 | Loss 0.0013 | Var 1.4615 | Cos 0.9177 | Time 1.96 min\nEpoch 23/100 | Loss 0.0014 | Var 1.4575 | Cos 0.9171 | Time 1.96 min\nEpoch 24/100 | Loss 0.0014 | Var 1.4573 | Cos 0.9166 | Time 1.96 min\nEpoch 25/100 | Loss 0.0013 | Var 1.4431 | Cos 0.9179 | Time 1.96 min\nEpoch 26/100 | Loss 0.0013 | Var 1.4240 | Cos 0.9185 | Time 1.96 min\nEpoch 27/100 | Loss 0.0013 | Var 1.4085 | Cos 0.9190 | Time 1.96 min\nEpoch 28/100 | Loss 0.0013 | Var 1.3960 | Cos 0.9194 | Time 1.96 min\nEpoch 29/100 | Loss 0.0013 | Var 1.3678 | Cos 0.9190 | Time 1.96 min\nEpoch 30/100 | Loss 0.0013 | Var 1.3526 | Cos 0.9188 | Time 1.96 min\nEpoch 31/100 | Loss 0.0012 | Var 1.3480 | Cos 0.9183 | Time 1.96 min\nEpoch 32/100 | Loss 0.0012 | Var 1.3366 | Cos 0.9181 | Time 1.96 min\nEpoch 33/100 | Loss 0.0012 | Var 1.3280 | Cos 0.9178 | Time 1.96 min\nEpoch 34/100 | Loss 0.0012 | Var 1.3152 | Cos 0.9190 | Time 1.96 min\nEpoch 35/100 | Loss 0.0012 | Var 1.3066 | Cos 0.9179 | Time 1.96 min\nEpoch 36/100 | Loss 0.0012 | Var 1.3000 | Cos 0.9182 | Time 1.96 min\nEpoch 37/100 | Loss 0.0012 | Var 1.2936 | Cos 0.9186 | Time 1.96 min\nEpoch 38/100 | Loss 0.0012 | Var 1.2730 | Cos 0.9182 | Time 1.96 min\nEpoch 39/100 | Loss 0.0012 | Var 1.2594 | Cos 0.9197 | Time 1.96 min\nEpoch 40/100 | Loss 0.0012 | Var 1.2574 | Cos 0.9191 | Time 1.96 min\nEpoch 41/100 | Loss 0.0012 | Var 1.2477 | Cos 0.9192 | Time 1.96 min\nEpoch 42/100 | Loss 0.0012 | Var 1.2439 | Cos 0.9201 | Time 1.96 min\nEpoch 43/100 | Loss 0.0012 | Var 1.2373 | Cos 0.9196 | Time 1.96 min\nEpoch 44/100 | Loss 0.0012 | Var 1.2258 | Cos 0.9194 | Time 1.96 min\nEpoch 45/100 | Loss 0.0012 | Var 1.2157 | Cos 0.9198 | Time 1.96 min\nEpoch 46/100 | Loss 0.0012 | Var 1.2107 | Cos 0.9206 | Time 1.96 min\nEpoch 47/100 | Loss 0.0012 | Var 1.1999 | Cos 0.9207 | Time 1.96 min\nEpoch 48/100 | Loss 0.0012 | Var 1.1965 | Cos 0.9211 | Time 1.96 min\nEpoch 49/100 | Loss 0.0012 | Var 1.1941 | Cos 0.9211 | Time 1.96 min\nEpoch 50/100 | Loss 0.0012 | Var 1.1833 | Cos 0.9211 | Time 1.96 min\nEpoch 51/100 | Loss 0.0011 | Var 1.1783 | Cos 0.9221 | Time 1.96 min\nEpoch 52/100 | Loss 0.0012 | Var 1.1670 | Cos 0.9221 | Time 1.96 min\nEpoch 53/100 | Loss 0.0012 | Var 1.1630 | Cos 0.9218 | Time 1.96 min\nEpoch 54/100 | Loss 0.0012 | Var 1.1582 | Cos 0.9211 | Time 1.96 min\nEpoch 55/100 | Loss 0.0011 | Var 1.1488 | Cos 0.9220 | Time 1.96 min\nEpoch 56/100 | Loss 0.0011 | Var 1.1420 | Cos 0.9214 | Time 1.96 min\nEpoch 57/100 | Loss 0.0011 | Var 1.1409 | Cos 0.9223 | Time 1.95 min\nEpoch 58/100 | Loss 0.0011 | Var 1.1333 | Cos 0.9225 | Time 1.96 min\nEpoch 59/100 | Loss 0.0011 | Var 1.1353 | Cos 0.9222 | Time 1.96 min\nEpoch 60/100 | Loss 0.0011 | Var 1.1251 | Cos 0.9227 | Time 1.96 min\nEpoch 61/100 | Loss 0.0011 | Var 1.1263 | Cos 0.9230 | Time 1.96 min\nEpoch 62/100 | Loss 0.0011 | Var 1.1270 | Cos 0.9236 | Time 1.96 min\nEpoch 63/100 | Loss 0.0011 | Var 1.1243 | Cos 0.9229 | Time 1.96 min\nEpoch 64/100 | Loss 0.0011 | Var 1.1197 | Cos 0.9224 | Time 1.96 min\nEpoch 65/100 | Loss 0.0011 | Var 1.1125 | Cos 0.9220 | Time 1.96 min\nEpoch 66/100 | Loss 0.0011 | Var 1.1088 | Cos 0.9229 | Time 1.96 min\nEpoch 67/100 | Loss 0.0011 | Var 1.1125 | Cos 0.9232 | Time 1.96 min\nEpoch 68/100 | Loss 0.0011 | Var 1.1067 | Cos 0.9234 | Time 1.96 min\nEpoch 69/100 | Loss 0.0011 | Var 1.0952 | Cos 0.9238 | Time 1.96 min\nEpoch 70/100 | Loss 0.0011 | Var 1.0926 | Cos 0.9235 | Time 1.96 min\nEpoch 71/100 | Loss 0.0011 | Var 1.0922 | Cos 0.9240 | Time 1.96 min\nEpoch 72/100 | Loss 0.0011 | Var 1.0859 | Cos 0.9251 | Time 1.96 min\nEpoch 73/100 | Loss 0.0011 | Var 1.0820 | Cos 0.9247 | Time 1.96 min\nEpoch 74/100 | Loss 0.0011 | Var 1.0810 | Cos 0.9243 | Time 1.96 min\nEpoch 75/100 | Loss 0.0011 | Var 1.0756 | Cos 0.9243 | Time 1.96 min\nEpoch 76/100 | Loss 0.0011 | Var 1.0695 | Cos 0.9234 | Time 1.96 min\nEpoch 77/100 | Loss 0.0011 | Var 1.0685 | Cos 0.9234 | Time 1.96 min\nEpoch 78/100 | Loss 0.0011 | Var 1.0685 | Cos 0.9241 | Time 1.96 min\nEpoch 79/100 | Loss 0.0011 | Var 1.0646 | Cos 0.9236 | Time 1.96 min\nEpoch 80/100 | Loss 0.0011 | Var 1.0609 | Cos 0.9245 | Time 1.96 min\nEpoch 81/100 | Loss 0.0011 | Var 1.0605 | Cos 0.9243 | Time 1.96 min\nEpoch 82/100 | Loss 0.0011 | Var 1.0629 | Cos 0.9240 | Time 1.96 min\nEpoch 83/100 | Loss 0.0011 | Var 1.0559 | Cos 0.9232 | Time 1.96 min\nEpoch 84/100 | Loss 0.0011 | Var 1.0538 | Cos 0.9240 | Time 1.96 min\nEpoch 85/100 | Loss 0.0011 | Var 1.0452 | Cos 0.9233 | Time 1.96 min\nEpoch 86/100 | Loss 0.0011 | Var 1.0454 | Cos 0.9243 | Time 1.96 min\nEpoch 87/100 | Loss 0.0011 | Var 1.0454 | Cos 0.9239 | Time 1.96 min\nEpoch 88/100 | Loss 0.0011 | Var 1.0459 | Cos 0.9245 | Time 1.96 min\nEpoch 89/100 | Loss 0.0011 | Var 1.0396 | Cos 0.9255 | Time 1.96 min\nEpoch 90/100 | Loss 0.0011 | Var 1.0401 | Cos 0.9243 | Time 1.96 min\nEpoch 91/100 | Loss 0.0011 | Var 1.0378 | Cos 0.9244 | Time 1.96 min\nEpoch 92/100 | Loss 0.0011 | Var 1.0361 | Cos 0.9246 | Time 1.96 min\nEpoch 93/100 | Loss 0.0011 | Var 1.0297 | Cos 0.9251 | Time 1.96 min\nEpoch 94/100 | Loss 0.0011 | Var 1.0290 | Cos 0.9252 | Time 1.95 min\nEpoch 95/100 | Loss 0.0011 | Var 1.0334 | Cos 0.9251 | Time 1.96 min\nEpoch 96/100 | Loss 0.0011 | Var 1.0270 | Cos 0.9248 | Time 1.96 min\nEpoch 97/100 | Loss 0.0011 | Var 1.0268 | Cos 0.9249 | Time 1.96 min\nEpoch 98/100 | Loss 0.0011 | Var 1.0316 | Cos 0.9257 | Time 1.96 min\nEpoch 99/100 | Loss 0.0011 | Var 1.0493 | Cos 0.9262 | Time 1.96 min\nEpoch 100/100 | Loss 0.0011 | Var 1.0605 | Cos 0.9257 | Time 1.96 min\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"torch.save(encoder.state_dict(), \"/kaggle/working/encoder_final.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T07:54:35.112614Z","iopub.execute_input":"2026-02-20T07:54:35.112938Z","iopub.status.idle":"2026-02-20T07:54:35.216957Z","shell.execute_reply.started":"2026-02-20T07:54:35.112900Z","shell.execute_reply":"2026-02-20T07:54:35.216078Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from torchvision import datasets, transforms\n\n# No augmentation for probe\nprobe_transform = transforms.ToTensor()\n\ntrain_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=True,\n    download=False,\n    transform=probe_transform\n)\n\ntest_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=False,\n    download=False,\n    transform=probe_transform\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=256,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n\nprint(\"Train batches:\", len(train_loader))\nprint(\"Test batches:\", len(test_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T07:54:35.217840Z","iopub.execute_input":"2026-02-20T07:54:35.218137Z","iopub.status.idle":"2026-02-20T07:54:36.238178Z","shell.execute_reply.started":"2026-02-20T07:54:35.218103Z","shell.execute_reply":"2026-02-20T07:54:36.237350Z"}},"outputs":[{"name":"stdout","text":"Train batches: 196\nTest batches: 40\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Load final SSL weights\nencoder = Encoder().to(device)\nencoder.load_state_dict(torch.load(\"/kaggle/working/encoder_final.pt\"))\nencoder.eval()\n\n# Freeze encoder\nfor p in encoder.parameters():\n    p.requires_grad = False\n\nprint(\"Encoder loaded and frozen.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T07:54:36.239111Z","iopub.execute_input":"2026-02-20T07:54:36.239391Z","iopub.status.idle":"2026-02-20T07:54:36.452489Z","shell.execute_reply.started":"2026-02-20T07:54:36.239369Z","shell.execute_reply":"2026-02-20T07:54:36.451891Z"}},"outputs":[{"name":"stdout","text":"Encoder loaded and frozen.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"\nclass LinearProbe(nn.Module):\n    def __init__(self, in_dim=512, num_classes=10):\n        super().__init__()\n        self.fc = nn.Linear(in_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\nprobe = LinearProbe(in_dim=512).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(probe.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T07:54:36.453408Z","iopub.execute_input":"2026-02-20T07:54:36.453664Z","iopub.status.idle":"2026-02-20T07:54:36.460217Z","shell.execute_reply.started":"2026-02-20T07:54:36.453618Z","shell.execute_reply":"2026-02-20T07:54:36.459616Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"probe_epochs = 100\n\nfor epoch in range(probe_epochs):\n    probe.train()\n    total_loss = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            features = encoder(images)\n\n        outputs = probe(features)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Probe Epoch {epoch+1}/{probe_epochs} | Loss {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T07:54:36.461069Z","iopub.execute_input":"2026-02-20T07:54:36.461283Z","iopub.status.idle":"2026-02-20T08:00:32.140612Z","shell.execute_reply.started":"2026-02-20T07:54:36.461261Z","shell.execute_reply":"2026-02-20T08:00:32.139947Z"}},"outputs":[{"name":"stdout","text":"Probe Epoch 1/100 | Loss 1.4681\nProbe Epoch 2/100 | Loss 1.3430\nProbe Epoch 3/100 | Loss 1.3191\nProbe Epoch 4/100 | Loss 1.3006\nProbe Epoch 5/100 | Loss 1.2859\nProbe Epoch 6/100 | Loss 1.2775\nProbe Epoch 7/100 | Loss 1.2715\nProbe Epoch 8/100 | Loss 1.2646\nProbe Epoch 9/100 | Loss 1.2573\nProbe Epoch 10/100 | Loss 1.2533\nProbe Epoch 11/100 | Loss 1.2490\nProbe Epoch 12/100 | Loss 1.2439\nProbe Epoch 13/100 | Loss 1.2435\nProbe Epoch 14/100 | Loss 1.2384\nProbe Epoch 15/100 | Loss 1.2388\nProbe Epoch 16/100 | Loss 1.2348\nProbe Epoch 17/100 | Loss 1.2319\nProbe Epoch 18/100 | Loss 1.2273\nProbe Epoch 19/100 | Loss 1.2267\nProbe Epoch 20/100 | Loss 1.2274\nProbe Epoch 21/100 | Loss 1.2226\nProbe Epoch 22/100 | Loss 1.2234\nProbe Epoch 23/100 | Loss 1.2202\nProbe Epoch 24/100 | Loss 1.2201\nProbe Epoch 25/100 | Loss 1.2201\nProbe Epoch 26/100 | Loss 1.2137\nProbe Epoch 27/100 | Loss 1.2153\nProbe Epoch 28/100 | Loss 1.2136\nProbe Epoch 29/100 | Loss 1.2135\nProbe Epoch 30/100 | Loss 1.2122\nProbe Epoch 31/100 | Loss 1.2113\nProbe Epoch 32/100 | Loss 1.2074\nProbe Epoch 33/100 | Loss 1.2084\nProbe Epoch 34/100 | Loss 1.2077\nProbe Epoch 35/100 | Loss 1.2064\nProbe Epoch 36/100 | Loss 1.2071\nProbe Epoch 37/100 | Loss 1.2025\nProbe Epoch 38/100 | Loss 1.2010\nProbe Epoch 39/100 | Loss 1.2056\nProbe Epoch 40/100 | Loss 1.1996\nProbe Epoch 41/100 | Loss 1.2021\nProbe Epoch 42/100 | Loss 1.1995\nProbe Epoch 43/100 | Loss 1.1985\nProbe Epoch 44/100 | Loss 1.1991\nProbe Epoch 45/100 | Loss 1.1970\nProbe Epoch 46/100 | Loss 1.1963\nProbe Epoch 47/100 | Loss 1.1971\nProbe Epoch 48/100 | Loss 1.1963\nProbe Epoch 49/100 | Loss 1.1940\nProbe Epoch 50/100 | Loss 1.1946\nProbe Epoch 51/100 | Loss 1.1951\nProbe Epoch 52/100 | Loss 1.1924\nProbe Epoch 53/100 | Loss 1.1930\nProbe Epoch 54/100 | Loss 1.1920\nProbe Epoch 55/100 | Loss 1.1919\nProbe Epoch 56/100 | Loss 1.1905\nProbe Epoch 57/100 | Loss 1.1906\nProbe Epoch 58/100 | Loss 1.1928\nProbe Epoch 59/100 | Loss 1.1905\nProbe Epoch 60/100 | Loss 1.1894\nProbe Epoch 61/100 | Loss 1.1880\nProbe Epoch 62/100 | Loss 1.1874\nProbe Epoch 63/100 | Loss 1.1884\nProbe Epoch 64/100 | Loss 1.1876\nProbe Epoch 65/100 | Loss 1.1851\nProbe Epoch 66/100 | Loss 1.1871\nProbe Epoch 67/100 | Loss 1.1849\nProbe Epoch 68/100 | Loss 1.1869\nProbe Epoch 69/100 | Loss 1.1829\nProbe Epoch 70/100 | Loss 1.1847\nProbe Epoch 71/100 | Loss 1.1856\nProbe Epoch 72/100 | Loss 1.1865\nProbe Epoch 73/100 | Loss 1.1830\nProbe Epoch 74/100 | Loss 1.1825\nProbe Epoch 75/100 | Loss 1.1820\nProbe Epoch 76/100 | Loss 1.1796\nProbe Epoch 77/100 | Loss 1.1825\nProbe Epoch 78/100 | Loss 1.1823\nProbe Epoch 79/100 | Loss 1.1829\nProbe Epoch 80/100 | Loss 1.1802\nProbe Epoch 81/100 | Loss 1.1814\nProbe Epoch 82/100 | Loss 1.1808\nProbe Epoch 83/100 | Loss 1.1798\nProbe Epoch 84/100 | Loss 1.1796\nProbe Epoch 85/100 | Loss 1.1793\nProbe Epoch 86/100 | Loss 1.1791\nProbe Epoch 87/100 | Loss 1.1794\nProbe Epoch 88/100 | Loss 1.1809\nProbe Epoch 89/100 | Loss 1.1762\nProbe Epoch 90/100 | Loss 1.1788\nProbe Epoch 91/100 | Loss 1.1815\nProbe Epoch 92/100 | Loss 1.1772\nProbe Epoch 93/100 | Loss 1.1779\nProbe Epoch 94/100 | Loss 1.1756\nProbe Epoch 95/100 | Loss 1.1741\nProbe Epoch 96/100 | Loss 1.1762\nProbe Epoch 97/100 | Loss 1.1742\nProbe Epoch 98/100 | Loss 1.1752\nProbe Epoch 99/100 | Loss 1.1767\nProbe Epoch 100/100 | Loss 1.1755\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"probe.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        features = encoder(images)\n        outputs = probe(features)\n\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"\\nðŸ”¹ Linear Probe Test Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T08:00:32.141879Z","iopub.execute_input":"2026-02-20T08:00:32.142182Z","iopub.status.idle":"2026-02-20T08:00:33.155471Z","shell.execute_reply.started":"2026-02-20T08:00:32.142148Z","shell.execute_reply":"2026-02-20T08:00:33.154732Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Linear Probe Test Accuracy: 55.16%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}