{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ncudnn.benchmark = True\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:04.938538Z","iopub.execute_input":"2026-02-20T04:38:04.938867Z","iopub.status.idle":"2026-02-20T04:38:13.350165Z","shell.execute_reply.started":"2026-02-20T04:38:04.938831Z","shell.execute_reply":"2026-02-20T04:38:13.349412Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"base_transform = transforms.ToTensor()\n\nssl_transform = transforms.Compose([\n    transforms.RandomResizedCrop(32),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n    transforms.ToTensor()\n])\n\nto_pil = transforms.ToPILImage()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:13.351789Z","iopub.execute_input":"2026-02-20T04:38:13.352518Z","iopub.status.idle":"2026-02-20T04:38:13.357463Z","shell.execute_reply.started":"2026-02-20T04:38:13.352491Z","shell.execute_reply":"2026-02-20T04:38:13.356682Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=True,\n    download=True,\n    transform=base_transform\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:13.358418Z","iopub.execute_input":"2026-02-20T04:38:13.358773Z","iopub.status.idle":"2026-02-20T04:38:14.409789Z","shell.execute_reply.started":"2026-02-20T04:38:13.358700Z","shell.execute_reply":"2026-02-20T04:38:14.409138Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"loader = DataLoader(\n    dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=True\n)\n\nprint(\"Batches per epoch:\", len(loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.410774Z","iopub.execute_input":"2026-02-20T04:38:14.411109Z","iopub.status.idle":"2026-02-20T04:38:14.416619Z","shell.execute_reply.started":"2026-02-20T04:38:14.411076Z","shell.execute_reply":"2026-02-20T04:38:14.415781Z"}},"outputs":[{"name":"stdout","text":"Batches per epoch: 195\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torchvision.models as models\n\nclass Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Load ResNet18\n        backbone = models.resnet18(weights=None)\n\n        # Remove final classification layer\n        self.encoder = nn.Sequential(*list(backbone.children())[:-1])\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x.view(x.size(0), -1)  # Output: (B, 512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.417561Z","iopub.execute_input":"2026-02-20T04:38:14.417874Z","iopub.status.idle":"2026-02-20T04:38:14.428194Z","shell.execute_reply.started":"2026-02-20T04:38:14.417832Z","shell.execute_reply":"2026-02-20T04:38:14.427405Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Predictor(nn.Module):\n    def __init__(self, dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.ReLU(),\n            nn.Linear(dim, dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.429051Z","iopub.execute_input":"2026-02-20T04:38:14.429345Z","iopub.status.idle":"2026-02-20T04:38:14.439007Z","shell.execute_reply.started":"2026-02-20T04:38:14.429323Z","shell.execute_reply":"2026-02-20T04:38:14.438297Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Projector(nn.Module):\n    def __init__(self, in_dim=512, hidden_dim=512, out_dim=256):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.441146Z","iopub.execute_input":"2026-02-20T04:38:14.441391Z","iopub.status.idle":"2026-02-20T04:38:14.450246Z","shell.execute_reply.started":"2026-02-20T04:38:14.441357Z","shell.execute_reply":"2026-02-20T04:38:14.449482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def ssl_loss(p, z):\n    p = F.normalize(p, dim=1)\n    z = F.normalize(z, dim=1)\n    return F.mse_loss(p, z)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T04:38:14.451161Z","iopub.execute_input":"2026-02-20T04:38:14.451402Z","iopub.status.idle":"2026-02-20T04:38:14.462434Z","shell.execute_reply.started":"2026-02-20T04:38:14.451380Z","shell.execute_reply":"2026-02-20T04:38:14.461780Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"encoder = Encoder().to(device)\nprojector = Projector().to(device)\npredictor = Predictor().to(device)\n\ntarget_encoder = Encoder().to(device)\ntarget_encoder.load_state_dict(encoder.state_dict())\n\nfor p in target_encoder.parameters():\n    p.requires_grad = False\n\noptimizer = torch.optim.Adam(\n    list(encoder.parameters()) +\n    list(projector.parameters()) +\n    list(predictor.parameters()),\n    lr=1e-3\n)\n\nema_tau = 0.996\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T08:05:54.940072Z","iopub.execute_input":"2026-02-20T08:05:54.940927Z","iopub.status.idle":"2026-02-20T08:05:55.306931Z","shell.execute_reply.started":"2026-02-20T08:05:54.940891Z","shell.execute_reply":"2026-02-20T08:05:55.306073Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"@torch.no_grad()\ndef feature_variance(z):\n    return z.var(dim=0).mean().item()\n\n@torch.no_grad()\ndef cosine_similarity_mean(z1, z2):\n    z1 = F.normalize(z1, dim=1)\n    z2 = F.normalize(z2, dim=1)\n    return (z1 * z2).sum(dim=1).mean().item()\n\n@torch.no_grad()\ndef update_target_encoder(online, target, tau):\n    for op, tp in zip(online.parameters(), target.parameters()):\n        tp.data = tau * tp.data + (1 - tau) * op.data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T08:06:02.704476Z","iopub.execute_input":"2026-02-20T08:06:02.704780Z","iopub.status.idle":"2026-02-20T08:06:02.710858Z","shell.execute_reply.started":"2026-02-20T08:06:02.704756Z","shell.execute_reply":"2026-02-20T08:06:02.710012Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"epochs = 100\nos.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n\nfor epoch in range(epochs):\n    start = time.time()\n\n    total_loss, total_var, total_cos = 0.0, 0.0, 0.0\n\n    for images, _ in loader:\n        images = images.to(device)\n\n        view1 = torch.stack([\n            ssl_transform(to_pil(img.cpu())) for img in images\n        ]).to(device)\n\n        view2 = torch.stack([\n            ssl_transform(to_pil(img.cpu())) for img in images\n        ]).to(device)\n\n        z1 = encoder(view1)\n        z2 = encoder(view2)\n\n        h1 = projector(z1)\n        h2 = projector(z2)\n\n        p1 = predictor(h1)\n        p2 = predictor(h2)\n\n        with torch.no_grad():\n            t1 = projector(target_encoder(view1))\n            t2 = projector(target_encoder(view2))\n\n        loss = ssl_loss(p1, t2.detach()) + ssl_loss(p2, t1.detach())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        update_target_encoder(encoder, target_encoder, ema_tau)\n\n        with torch.no_grad():\n            total_var += feature_variance(z1)\n            total_cos += cosine_similarity_mean(z1, z2)\n\n        total_loss += loss.item()\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Loss {total_loss/len(loader):.4f} | \"\n        f\"Var {total_var/len(loader):.4f} | \"\n        f\"Cos {total_cos/len(loader):.4f} | \"\n        f\"Time {(time.time()-start)/60:.2f} min\"\n    )\n\n    torch.save(\n        encoder.state_dict(),\n        f\"/kaggle/working/checkpoints/encoder_epoch_{epoch+1}.pt\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T08:06:11.376490Z","iopub.execute_input":"2026-02-20T08:06:11.376799Z","iopub.status.idle":"2026-02-20T11:22:35.568957Z","shell.execute_reply.started":"2026-02-20T08:06:11.376773Z","shell.execute_reply":"2026-02-20T11:22:35.568106Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100 | Loss 0.0009 | Var 2.2349 | Cos 0.6894 | Time 1.96 min\nEpoch 2/100 | Loss 0.0007 | Var 1.9018 | Cos 0.7820 | Time 1.96 min\nEpoch 3/100 | Loss 0.0008 | Var 1.8067 | Cos 0.8282 | Time 1.96 min\nEpoch 4/100 | Loss 0.0010 | Var 1.7264 | Cos 0.8503 | Time 1.96 min\nEpoch 5/100 | Loss 0.0011 | Var 1.6807 | Cos 0.8667 | Time 1.96 min\nEpoch 6/100 | Loss 0.0011 | Var 1.6395 | Cos 0.8764 | Time 1.99 min\nEpoch 7/100 | Loss 0.0012 | Var 1.6545 | Cos 0.8830 | Time 1.96 min\nEpoch 8/100 | Loss 0.0012 | Var 1.6519 | Cos 0.8912 | Time 1.96 min\nEpoch 9/100 | Loss 0.0012 | Var 1.6551 | Cos 0.8978 | Time 1.96 min\nEpoch 10/100 | Loss 0.0012 | Var 1.6402 | Cos 0.9016 | Time 1.96 min\nEpoch 11/100 | Loss 0.0012 | Var 1.6293 | Cos 0.9053 | Time 1.96 min\nEpoch 12/100 | Loss 0.0013 | Var 1.6189 | Cos 0.9061 | Time 1.96 min\nEpoch 13/100 | Loss 0.0013 | Var 1.6003 | Cos 0.9071 | Time 1.96 min\nEpoch 14/100 | Loss 0.0013 | Var 1.5803 | Cos 0.9075 | Time 1.96 min\nEpoch 15/100 | Loss 0.0013 | Var 1.5606 | Cos 0.9101 | Time 1.96 min\nEpoch 16/100 | Loss 0.0013 | Var 1.5580 | Cos 0.9111 | Time 1.96 min\nEpoch 17/100 | Loss 0.0013 | Var 1.5482 | Cos 0.9111 | Time 1.96 min\nEpoch 18/100 | Loss 0.0013 | Var 1.5364 | Cos 0.9123 | Time 1.96 min\nEpoch 19/100 | Loss 0.0013 | Var 1.5242 | Cos 0.9143 | Time 1.96 min\nEpoch 20/100 | Loss 0.0013 | Var 1.5345 | Cos 0.9148 | Time 1.96 min\nEpoch 21/100 | Loss 0.0013 | Var 1.5192 | Cos 0.9167 | Time 1.96 min\nEpoch 22/100 | Loss 0.0014 | Var 1.5153 | Cos 0.9169 | Time 1.96 min\nEpoch 23/100 | Loss 0.0014 | Var 1.5038 | Cos 0.9171 | Time 1.96 min\nEpoch 24/100 | Loss 0.0014 | Var 1.4923 | Cos 0.9188 | Time 1.96 min\nEpoch 25/100 | Loss 0.0014 | Var 1.4920 | Cos 0.9200 | Time 1.96 min\nEpoch 26/100 | Loss 0.0014 | Var 1.4781 | Cos 0.9205 | Time 1.96 min\nEpoch 27/100 | Loss 0.0014 | Var 1.4795 | Cos 0.9213 | Time 1.96 min\nEpoch 28/100 | Loss 0.0014 | Var 1.4779 | Cos 0.9212 | Time 1.96 min\nEpoch 29/100 | Loss 0.0013 | Var 1.4757 | Cos 0.9228 | Time 1.96 min\nEpoch 30/100 | Loss 0.0013 | Var 1.4620 | Cos 0.9225 | Time 1.96 min\nEpoch 31/100 | Loss 0.0013 | Var 1.4426 | Cos 0.9236 | Time 1.96 min\nEpoch 32/100 | Loss 0.0013 | Var 1.4298 | Cos 0.9241 | Time 1.97 min\nEpoch 33/100 | Loss 0.0013 | Var 1.4287 | Cos 0.9242 | Time 1.96 min\nEpoch 34/100 | Loss 0.0013 | Var 1.4092 | Cos 0.9241 | Time 1.96 min\nEpoch 35/100 | Loss 0.0013 | Var 1.4090 | Cos 0.9246 | Time 1.96 min\nEpoch 36/100 | Loss 0.0013 | Var 1.3911 | Cos 0.9259 | Time 1.97 min\nEpoch 37/100 | Loss 0.0013 | Var 1.3797 | Cos 0.9253 | Time 1.96 min\nEpoch 38/100 | Loss 0.0012 | Var 1.3819 | Cos 0.9257 | Time 1.96 min\nEpoch 39/100 | Loss 0.0012 | Var 1.3730 | Cos 0.9263 | Time 1.96 min\nEpoch 40/100 | Loss 0.0012 | Var 1.3585 | Cos 0.9270 | Time 1.96 min\nEpoch 41/100 | Loss 0.0012 | Var 1.3571 | Cos 0.9276 | Time 1.96 min\nEpoch 42/100 | Loss 0.0012 | Var 1.3372 | Cos 0.9274 | Time 1.96 min\nEpoch 43/100 | Loss 0.0012 | Var 1.3232 | Cos 0.9282 | Time 1.96 min\nEpoch 44/100 | Loss 0.0012 | Var 1.3227 | Cos 0.9286 | Time 1.96 min\nEpoch 45/100 | Loss 0.0012 | Var 1.3161 | Cos 0.9288 | Time 1.96 min\nEpoch 46/100 | Loss 0.0012 | Var 1.3139 | Cos 0.9291 | Time 1.97 min\nEpoch 47/100 | Loss 0.0012 | Var 1.3042 | Cos 0.9302 | Time 1.97 min\nEpoch 48/100 | Loss 0.0012 | Var 1.2925 | Cos 0.9286 | Time 1.97 min\nEpoch 49/100 | Loss 0.0012 | Var 1.2746 | Cos 0.9297 | Time 1.96 min\nEpoch 50/100 | Loss 0.0012 | Var 1.2668 | Cos 0.9299 | Time 1.96 min\nEpoch 51/100 | Loss 0.0012 | Var 1.2650 | Cos 0.9287 | Time 1.96 min\nEpoch 52/100 | Loss 0.0011 | Var 1.2642 | Cos 0.9298 | Time 1.96 min\nEpoch 53/100 | Loss 0.0011 | Var 1.2559 | Cos 0.9295 | Time 1.96 min\nEpoch 54/100 | Loss 0.0012 | Var 1.2503 | Cos 0.9296 | Time 1.96 min\nEpoch 55/100 | Loss 0.0011 | Var 1.2504 | Cos 0.9309 | Time 1.96 min\nEpoch 56/100 | Loss 0.0011 | Var 1.2454 | Cos 0.9309 | Time 1.96 min\nEpoch 57/100 | Loss 0.0011 | Var 1.2374 | Cos 0.9303 | Time 1.96 min\nEpoch 58/100 | Loss 0.0011 | Var 1.2273 | Cos 0.9315 | Time 1.96 min\nEpoch 59/100 | Loss 0.0011 | Var 1.2154 | Cos 0.9315 | Time 1.96 min\nEpoch 60/100 | Loss 0.0011 | Var 1.2118 | Cos 0.9314 | Time 1.96 min\nEpoch 61/100 | Loss 0.0011 | Var 1.2122 | Cos 0.9317 | Time 1.96 min\nEpoch 62/100 | Loss 0.0011 | Var 1.2066 | Cos 0.9319 | Time 1.96 min\nEpoch 63/100 | Loss 0.0011 | Var 1.1929 | Cos 0.9318 | Time 1.96 min\nEpoch 64/100 | Loss 0.0011 | Var 1.1812 | Cos 0.9316 | Time 1.96 min\nEpoch 65/100 | Loss 0.0011 | Var 1.1785 | Cos 0.9318 | Time 1.96 min\nEpoch 66/100 | Loss 0.0011 | Var 1.1789 | Cos 0.9324 | Time 1.96 min\nEpoch 67/100 | Loss 0.0011 | Var 1.1841 | Cos 0.9321 | Time 1.96 min\nEpoch 68/100 | Loss 0.0011 | Var 1.1769 | Cos 0.9315 | Time 1.96 min\nEpoch 69/100 | Loss 0.0010 | Var 1.1704 | Cos 0.9317 | Time 1.96 min\nEpoch 70/100 | Loss 0.0011 | Var 1.1551 | Cos 0.9327 | Time 1.96 min\nEpoch 71/100 | Loss 0.0011 | Var 1.1499 | Cos 0.9323 | Time 1.96 min\nEpoch 72/100 | Loss 0.0011 | Var 1.1459 | Cos 0.9319 | Time 1.96 min\nEpoch 73/100 | Loss 0.0011 | Var 1.1398 | Cos 0.9320 | Time 1.97 min\nEpoch 74/100 | Loss 0.0011 | Var 1.1402 | Cos 0.9326 | Time 1.96 min\nEpoch 75/100 | Loss 0.0011 | Var 1.1282 | Cos 0.9321 | Time 1.96 min\nEpoch 76/100 | Loss 0.0011 | Var 1.1325 | Cos 0.9327 | Time 1.96 min\nEpoch 77/100 | Loss 0.0010 | Var 1.1284 | Cos 0.9339 | Time 1.96 min\nEpoch 78/100 | Loss 0.0010 | Var 1.1254 | Cos 0.9334 | Time 1.96 min\nEpoch 79/100 | Loss 0.0011 | Var 1.1230 | Cos 0.9333 | Time 1.96 min\nEpoch 80/100 | Loss 0.0011 | Var 1.1240 | Cos 0.9330 | Time 1.97 min\nEpoch 81/100 | Loss 0.0011 | Var 1.1223 | Cos 0.9338 | Time 1.96 min\nEpoch 82/100 | Loss 0.0010 | Var 1.1176 | Cos 0.9339 | Time 1.96 min\nEpoch 83/100 | Loss 0.0010 | Var 1.1152 | Cos 0.9335 | Time 1.96 min\nEpoch 84/100 | Loss 0.0011 | Var 1.1113 | Cos 0.9326 | Time 1.96 min\nEpoch 85/100 | Loss 0.0011 | Var 1.1085 | Cos 0.9333 | Time 1.96 min\nEpoch 86/100 | Loss 0.0011 | Var 1.1054 | Cos 0.9334 | Time 1.96 min\nEpoch 87/100 | Loss 0.0010 | Var 1.0970 | Cos 0.9342 | Time 1.96 min\nEpoch 88/100 | Loss 0.0011 | Var 1.0931 | Cos 0.9337 | Time 1.96 min\nEpoch 89/100 | Loss 0.0010 | Var 1.0934 | Cos 0.9348 | Time 1.96 min\nEpoch 90/100 | Loss 0.0011 | Var 1.0906 | Cos 0.9339 | Time 1.96 min\nEpoch 91/100 | Loss 0.0010 | Var 1.0835 | Cos 0.9345 | Time 1.96 min\nEpoch 92/100 | Loss 0.0011 | Var 1.0851 | Cos 0.9343 | Time 1.96 min\nEpoch 93/100 | Loss 0.0011 | Var 1.0822 | Cos 0.9346 | Time 1.96 min\nEpoch 94/100 | Loss 0.0010 | Var 1.0761 | Cos 0.9352 | Time 1.96 min\nEpoch 95/100 | Loss 0.0010 | Var 1.0694 | Cos 0.9354 | Time 1.96 min\nEpoch 96/100 | Loss 0.0010 | Var 1.0697 | Cos 0.9356 | Time 1.96 min\nEpoch 97/100 | Loss 0.0010 | Var 1.0681 | Cos 0.9347 | Time 1.96 min\nEpoch 98/100 | Loss 0.0010 | Var 1.0672 | Cos 0.9353 | Time 1.96 min\nEpoch 99/100 | Loss 0.0010 | Var 1.0633 | Cos 0.9358 | Time 1.96 min\nEpoch 100/100 | Loss 0.0010 | Var 1.0594 | Cos 0.9345 | Time 1.96 min\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"torch.save(encoder.state_dict(), \"/kaggle/working/encoder_final.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:25:09.893658Z","iopub.execute_input":"2026-02-20T11:25:09.894326Z","iopub.status.idle":"2026-02-20T11:25:10.004015Z","shell.execute_reply.started":"2026-02-20T11:25:09.894294Z","shell.execute_reply":"2026-02-20T11:25:10.003085Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from torchvision import datasets, transforms\n\n# No augmentation for probe\nprobe_transform = transforms.ToTensor()\n\ntrain_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=True,\n    download=False,\n    transform=probe_transform\n)\n\ntest_dataset = datasets.CIFAR10(\n    root=\"/kaggle/working/data\",\n    train=False,\n    download=False,\n    transform=probe_transform\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=256,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=256,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n\nprint(\"Train batches:\", len(train_loader))\nprint(\"Test batches:\", len(test_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:25:21.150892Z","iopub.execute_input":"2026-02-20T11:25:21.151679Z","iopub.status.idle":"2026-02-20T11:25:22.163566Z","shell.execute_reply.started":"2026-02-20T11:25:21.151621Z","shell.execute_reply":"2026-02-20T11:25:22.162986Z"}},"outputs":[{"name":"stdout","text":"Train batches: 196\nTest batches: 40\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Load final SSL weights\nencoder = Encoder().to(device)\nencoder.load_state_dict(torch.load(\"/kaggle/working/encoder_final.pt\"))\nencoder.eval()\n\n# Freeze encoder\nfor p in encoder.parameters():\n    p.requires_grad = False\n\nprint(\"Encoder loaded and frozen.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:25:24.508297Z","iopub.execute_input":"2026-02-20T11:25:24.508908Z","iopub.status.idle":"2026-02-20T11:25:24.731826Z","shell.execute_reply.started":"2026-02-20T11:25:24.508883Z","shell.execute_reply":"2026-02-20T11:25:24.730897Z"}},"outputs":[{"name":"stdout","text":"Encoder loaded and frozen.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\nclass LinearProbe(nn.Module):\n    def __init__(self, in_dim=512, num_classes=10):\n        super().__init__()\n        self.fc = nn.Linear(in_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\nprobe = LinearProbe(in_dim=512).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(probe.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:25:28.153214Z","iopub.execute_input":"2026-02-20T11:25:28.154004Z","iopub.status.idle":"2026-02-20T11:25:28.160909Z","shell.execute_reply.started":"2026-02-20T11:25:28.153974Z","shell.execute_reply":"2026-02-20T11:25:28.160197Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"probe_epochs = 100\n\nfor epoch in range(probe_epochs):\n    probe.train()\n    total_loss = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            features = encoder(images)\n\n        outputs = probe(features)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Probe Epoch {epoch+1}/{probe_epochs} | Loss {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:25:30.762280Z","iopub.execute_input":"2026-02-20T11:25:30.762904Z","iopub.status.idle":"2026-02-20T11:31:29.586270Z","shell.execute_reply.started":"2026-02-20T11:25:30.762875Z","shell.execute_reply":"2026-02-20T11:31:29.585445Z"}},"outputs":[{"name":"stdout","text":"Probe Epoch 1/100 | Loss 1.5714\nProbe Epoch 2/100 | Loss 1.4619\nProbe Epoch 3/100 | Loss 1.4339\nProbe Epoch 4/100 | Loss 1.4191\nProbe Epoch 5/100 | Loss 1.4099\nProbe Epoch 6/100 | Loss 1.3977\nProbe Epoch 7/100 | Loss 1.3935\nProbe Epoch 8/100 | Loss 1.3847\nProbe Epoch 9/100 | Loss 1.3816\nProbe Epoch 10/100 | Loss 1.3752\nProbe Epoch 11/100 | Loss 1.3715\nProbe Epoch 12/100 | Loss 1.3679\nProbe Epoch 13/100 | Loss 1.3628\nProbe Epoch 14/100 | Loss 1.3600\nProbe Epoch 15/100 | Loss 1.3562\nProbe Epoch 16/100 | Loss 1.3569\nProbe Epoch 17/100 | Loss 1.3535\nProbe Epoch 18/100 | Loss 1.3488\nProbe Epoch 19/100 | Loss 1.3493\nProbe Epoch 20/100 | Loss 1.3486\nProbe Epoch 21/100 | Loss 1.3432\nProbe Epoch 22/100 | Loss 1.3433\nProbe Epoch 23/100 | Loss 1.3425\nProbe Epoch 24/100 | Loss 1.3389\nProbe Epoch 25/100 | Loss 1.3351\nProbe Epoch 26/100 | Loss 1.3367\nProbe Epoch 27/100 | Loss 1.3349\nProbe Epoch 28/100 | Loss 1.3338\nProbe Epoch 29/100 | Loss 1.3321\nProbe Epoch 30/100 | Loss 1.3321\nProbe Epoch 31/100 | Loss 1.3274\nProbe Epoch 32/100 | Loss 1.3271\nProbe Epoch 33/100 | Loss 1.3256\nProbe Epoch 34/100 | Loss 1.3267\nProbe Epoch 35/100 | Loss 1.3229\nProbe Epoch 36/100 | Loss 1.3265\nProbe Epoch 37/100 | Loss 1.3220\nProbe Epoch 38/100 | Loss 1.3218\nProbe Epoch 39/100 | Loss 1.3196\nProbe Epoch 40/100 | Loss 1.3192\nProbe Epoch 41/100 | Loss 1.3187\nProbe Epoch 42/100 | Loss 1.3169\nProbe Epoch 43/100 | Loss 1.3169\nProbe Epoch 44/100 | Loss 1.3182\nProbe Epoch 45/100 | Loss 1.3142\nProbe Epoch 46/100 | Loss 1.3118\nProbe Epoch 47/100 | Loss 1.3126\nProbe Epoch 48/100 | Loss 1.3135\nProbe Epoch 49/100 | Loss 1.3136\nProbe Epoch 50/100 | Loss 1.3136\nProbe Epoch 51/100 | Loss 1.3085\nProbe Epoch 52/100 | Loss 1.3109\nProbe Epoch 53/100 | Loss 1.3126\nProbe Epoch 54/100 | Loss 1.3076\nProbe Epoch 55/100 | Loss 1.3081\nProbe Epoch 56/100 | Loss 1.3057\nProbe Epoch 57/100 | Loss 1.3093\nProbe Epoch 58/100 | Loss 1.3057\nProbe Epoch 59/100 | Loss 1.3055\nProbe Epoch 60/100 | Loss 1.3063\nProbe Epoch 61/100 | Loss 1.3070\nProbe Epoch 62/100 | Loss 1.3025\nProbe Epoch 63/100 | Loss 1.3055\nProbe Epoch 64/100 | Loss 1.3032\nProbe Epoch 65/100 | Loss 1.3003\nProbe Epoch 66/100 | Loss 1.3016\nProbe Epoch 67/100 | Loss 1.3032\nProbe Epoch 68/100 | Loss 1.3030\nProbe Epoch 69/100 | Loss 1.2997\nProbe Epoch 70/100 | Loss 1.2993\nProbe Epoch 71/100 | Loss 1.2999\nProbe Epoch 72/100 | Loss 1.3010\nProbe Epoch 73/100 | Loss 1.2953\nProbe Epoch 74/100 | Loss 1.2978\nProbe Epoch 75/100 | Loss 1.2965\nProbe Epoch 76/100 | Loss 1.2980\nProbe Epoch 77/100 | Loss 1.2977\nProbe Epoch 78/100 | Loss 1.3000\nProbe Epoch 79/100 | Loss 1.2951\nProbe Epoch 80/100 | Loss 1.2943\nProbe Epoch 81/100 | Loss 1.2948\nProbe Epoch 82/100 | Loss 1.2948\nProbe Epoch 83/100 | Loss 1.2964\nProbe Epoch 84/100 | Loss 1.2962\nProbe Epoch 85/100 | Loss 1.2919\nProbe Epoch 86/100 | Loss 1.2934\nProbe Epoch 87/100 | Loss 1.2921\nProbe Epoch 88/100 | Loss 1.2931\nProbe Epoch 89/100 | Loss 1.2920\nProbe Epoch 90/100 | Loss 1.2916\nProbe Epoch 91/100 | Loss 1.2894\nProbe Epoch 92/100 | Loss 1.2915\nProbe Epoch 93/100 | Loss 1.2916\nProbe Epoch 94/100 | Loss 1.2891\nProbe Epoch 95/100 | Loss 1.2927\nProbe Epoch 96/100 | Loss 1.2895\nProbe Epoch 97/100 | Loss 1.2886\nProbe Epoch 98/100 | Loss 1.2920\nProbe Epoch 99/100 | Loss 1.2894\nProbe Epoch 100/100 | Loss 1.2897\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"probe.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        features = encoder(images)\n        outputs = probe(features)\n\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"\\nðŸ”¹ Linear Probe Test Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T11:31:40.365036Z","iopub.execute_input":"2026-02-20T11:31:40.365772Z","iopub.status.idle":"2026-02-20T11:31:41.230850Z","shell.execute_reply.started":"2026-02-20T11:31:40.365738Z","shell.execute_reply":"2026-02-20T11:31:41.229980Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Linear Probe Test Accuracy: 51.54%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}